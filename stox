#!/usr/bin/env python3
# Stox, a prediction engine for financial time series data
# Copyright (C) 2017-2020 Gokalp Ozcan

import pandas as pd
import argparse, datetime, os, sys, psutil
from zipfile import ZipFile
from time import perf_counter
from sklearn.metrics import mean_absolute_error, explained_variance_score
from sklearn.preprocessing import MinMaxScaler
from lightgbm import LGBMRegressor
import lib.tickers as ticker_lists
from lib.db import db_engine
from joblib import dump, load

BASE_DIR = os.path.dirname(os.path.realpath(__file__))
pd.set_option('mode.chained_assignment', None)

now = datetime.datetime.now()
day_of_week = now.strftime("%a").upper()
day_of_week = 'FRI' if day_of_week in ['SAT', 'SUN'] else day_of_week
TIMESTAMP = now.strftime("%Y-%m-%d-%H-%M-%S")

parser = argparse.ArgumentParser()
parser.add_argument('-m', '--markets', default='AU', help='Comma-separated list of markets. Default : AU')
parser.add_argument('-s', '--split-date', default='2016-01-01', help='Train/Test split date. Default : 2016-01-01')
parser.add_argument('-t', '--size', default=200, help='Number of estimator trees to build. Default: 200.')
parser.add_argument('-r', '--seed', default=6, help='Seed for initialising the model weights with')
parser.add_argument('-v', '--verbose', default=1, help='Integer greater than zero. Greater this number, more info is printed during run. Default: 1.')
parser.add_argument('-b', '--lookback', default=6, help='The number of periods for look-back features. Default: 6.')
parser.add_argument('-f', '--lookfwd', default=1, help='The number of periods into the future to predict at. Default: 1.')
parser.add_argument('-w', '--resample', default=f'W-{day_of_week}', help="Resampling window size. 'no' to turn off resampling, or any pandas-format resampling specification. Default: weekly resampling on current business day.")
parser.add_argument('-g', '--grid-search', default=False, help='Enable grid search of hyperparameters. Default: disabled', action='store_true')
parser.add_argument('-d', '--dump-data', default=False, help='Dump the datasets, predictions and results into parquet files. Default: False', action='store_true')
parser.add_argument('-l', '--load-data', default=False, help='Load the datasets from the last dump. Default: False', action='store_true')
parser.add_argument('-a', '--save-model', default=False, help='Save the trained model to a file. Default: False', action='store_true')
parser.add_argument('-o', '--load-model', default=False, help='Load a trained model from a file. Default: False', action='store_true')
parser.add_argument('-p', '--predict', default=False, help='Make predictions. Default: False', action='store_true')
parser.add_argument('-e', '--save-predictions', default=False, help='Save predictions on test data to a CSV file. Default: False', action='store_true')
parser.add_argument('-i', '--intraday-predictions', default=False, help='Fetch and make predictions on intraday data. Default: False', action='store_true')

MARKETS = parser.parse_args().markets
SPLIT_DATE = parser.parse_args().split_date
SIZE = int(parser.parse_args().size)
SEED = int(parser.parse_args().seed)
VERBOSE = int(parser.parse_args().verbose)
LOOKBACK = int(parser.parse_args().lookback)
LOOKFWD = int(parser.parse_args().lookfwd)
RESAMPLE = parser.parse_args().resample
GRID_SEARCH = parser.parse_args().grid_search
DUMP_DATA = parser.parse_args().dump_data
LOAD_DATA = parser.parse_args().load_data
SAVE_MODEL = parser.parse_args().save_model
LOAD_MODEL = parser.parse_args().load_model
PREDICT = parser.parse_args().predict
SAVE_PREDICTIONS = parser.parse_args().save_predictions
INTRADAY_PREDICTIONS = parser.parse_args().intraday_predictions

FEATURE_SUBSAMPLE = 1.0
MIN_TEST_SAMPLES = 10 # minimum number of test samples required for an individual ticker to bother calculating its alpha and making predictions
STAMP = f"{MARKETS.replace(',', '-')}_{LOOKBACK}_{RESAMPLE}_{LOOKFWD}" # to be used in naming dataset & model dump files
TICKERS = ticker_lists.by_market([ f"'{m}'" for m in MARKETS.split(',')])

print('Stox started on', TIMESTAMP, 'for', len(TICKERS), 'tickers in markets', MARKETS)
print('resampling window:', RESAMPLE, 'Lookback:', LOOKBACK, 'Lookforward:', LOOKFWD)

if LOAD_DATA:
    ds_train = load(f'{BASE_DIR}/ds_dumps/ds_train_{STAMP}.bin')
    ds_test  = load(f'{BASE_DIR}/ds_dumps/ds_test_{STAMP}.bin')
else:
    from dataset import DataSet
    ds_train = DataSet(tickers=TICKERS, lookback=LOOKBACK, lookfwd=LOOKFWD, predicate=f"date < '{SPLIT_DATE}'" , resample=RESAMPLE).data
    ds_test  = DataSet(tickers=TICKERS, lookback=LOOKBACK, lookfwd=LOOKFWD, predicate=f"date >= '{SPLIT_DATE}'", resample=RESAMPLE, keep_predictors=True, intraday=INTRADAY_PREDICTIONS).data

if VERBOSE > 0:
    print('\n--------------------------- Train dataset ---------------------------')
    print(ds_train.describe())
    print(ds_train.info(memory_usage='deep'))
    print('\n--------------------------- Test dataset ----------------------------')
    print(ds_test.describe())
    print(ds_test.info(memory_usage='deep'))

if DUMP_DATA:
    dump(ds_train, f'{BASE_DIR}/ds_dumps/ds_train_{STAMP}.bin', compress=True)
    dump(ds_test , f'{BASE_DIR}/ds_dumps/ds_test_{STAMP}.bin', compress=True)

features = [ f for f in list(ds_train.columns) if f.startswith('f_') ]

X_train = ds_train[features]
y_train = ds_train['future']

X_test = ds_test[features]
y_test = ds_test['future']

predictors = X_test[y_test.isnull()]
predictors = predictors.loc[[predictors.index.levels[0].max(), ]]
X_test.drop(predictors.index, inplace=True)
y_test.drop(predictors.index, inplace=True)

train_samples, test_samples, total_samples = len(X_train), len(X_test), len(X_train) + len(X_test)
print(  'X_train:', X_train.shape, 'X_test:', X_test.shape,
        'y_train:', y_train.shape, 'y_test:', y_test.shape,
        'predictors:', predictors.shape, '-',
        round(100 * train_samples / total_samples), '/', round(100 * test_samples / total_samples), '% split')

if not LOAD_MODEL:
    LGB_params = {  'boosting_type': 'gbdt', 'colsample_bytree': 0.6,
                    'min_child_samples': 20, 'min_child_weight': 0.001,
                    'num_leaves': 63, 'learning_rate': 0.1,
                    'reg_alpha': 0.001, 'reg_lambda': 1, 'objective': 'mae' }
    common_params = { 'n_estimators': SIZE, 'random_state': SEED, 'verbose': VERBOSE, 'n_jobs': -1 }

    model = LGBMRegressor(**LGB_params, **common_params)

    if GRID_SEARCH:
        from hypopt import GridSearch
        param_grid = [{
            #'n_estimators': [ SIZE ],
            #'objective': [ 'mae' ],
            #'boosting_type': [ 'gbdt', 'dart', 'goss' ], # 'rf' was broken
            #'num_leaves': [ 31, 63, 127 ],
            # 'learning_rate': [ 0.05, 0.1, 0.15 ],
            # 'subsample_for_bin': [ 200000, 500000 ],
            #'min_child_samples': [ 15, 20, 25 ],
            #'min_child_weight': [ 0.001, 0.01, 0.1 ],
            #'min_split_gain': [ 0.0, 0.001, 0.01 ],
            #'colsample_bytree': [ 1.0, 0.9, 0.8, 0.7, 0.6 ],
            #'reg_alpha': [ 0.001, 0.01, 0.1 ],
            #'reg_lambda': [ 0.01, 0.1, 1],
            'verbosity': [ 0 ],
        }]
        model = GridSearch(model=model, param_grid=param_grid, parallelize=False, seed=SEED)

    time_start_tr = perf_counter()

    if not GRID_SEARCH:
        model.fit(X_train, y_train)
    else:
        model.fit(X_train, y_train, X_test, y_test, scoring='neg_mean_absolute_error', verbose=True)
        print('BEST PARAMETERS:', model.get_best_params(), sep='\n')
        print('BEST MODEL:', model.best_estimator_, sep='\n')

    print('Training took', round(perf_counter() - time_start_tr, 2), 'seconds')
else:
    model = load(f'{BASE_DIR}/models/{STAMP}.bin')

if hasattr(model, 'feature_importances_') and (VERBOSE > 0 or FEATURE_SUBSAMPLE < 1.0):
    fi = pd.DataFrame(model.feature_importances_, index=features, columns=['importance']).sort_values('importance', ascending=False)
    print(fi)
    if FEATURE_SUBSAMPLE < 1.0:
        important_features = list(fi.head(round(len(features) * FEATURE_SUBSAMPLE)).index)
        if VERBOSE > 1:
            print('important features:', important_features, f'({len(important_features)})')
        unimportant_features = [ f for f in features if f not in important_features]
        
        X_train.drop(unimportant_features, axis=1, inplace=True)
        X_test.drop(unimportant_features, axis=1, inplace=True)
        predictors.drop(unimportant_features, axis=1, inplace=True)

        model = LGBMRegressor(**LGB_params, **common_params)
        model.fit(X_train, y_train) # fit a new model on reduced set of features

if SAVE_MODEL:
    dump(model, f'{BASE_DIR}/models/{STAMP}.bin', compress=True)

if PREDICT:
    results = pd.DataFrame()
    for t, p in predictors.groupby(level=1):
        if p.isnull().values.any():
            print('Not predicting', t, 'as it has NaN in its predictor.')
            continue

        try:
            xT, yT = X_test.xs(t, level=1, drop_level=False), y_test.xs(t, level=1, drop_level=False)
        except KeyError:
            continue

        if len(yT) < MIN_TEST_SAMPLES:
            print('Not predicting', t, 'as it has less than', MIN_TEST_SAMPLES, 'samples.')
            continue

        predictions = model.predict(xT)
        results.at[t, 'predicted_at'] = p.index[0][0]
        results.at[t, 'prediction'] = model.predict(p)[0]
        results.at[t, 'volatility'] = abs(yT).mean()
        results.at[t, 'MAE'] = mean_absolute_error(yT, predictions)
        results.at[t, 'alpha'] = (results.loc[t, 'volatility'] / results.loc[t, 'MAE'] - 1) * 100
        results.at[t, 'var_score'] = explained_variance_score(yT, predictions)
        results.at[t, 'test_samples'] = xT.shape[0]
        results.at[t, 'potential'] = results.loc[t, 'prediction'] * \
                                    (results.loc[t, 'var_score'] if results.loc[t, 'var_score'] > 0 else 0) * \
                                    (results.loc[t, 'alpha'] if results.loc[t, 'alpha'] > 0 else 0)

    results.index.rename('ticker', inplace=True)
    results = results.sort_values('potential', ascending=False).round(2)
    print(results, results.describe(), sep='\n')
    results.to_csv(f'{BASE_DIR}/results/{TIMESTAMP}.csv')
    results.reset_index().to_sql(STAMP, if_exists='replace', schema='results', index=False, con=db_engine())

# Calculate and print prediction results on the test data
predictions_on_test = model.predict(X_test)
volatility_on_test = round(abs(y_test).mean(), 4)
error_on_test = round(mean_absolute_error(y_test, predictions_on_test), 4)
print('Overall volatility:', volatility_on_test, ', error:', error_on_test, ', alpha:', round((volatility_on_test / error_on_test - 1) * 100, 2))

if SAVE_PREDICTIONS:
    y_test = pd.concat([y_test, pd.DataFrame(predictions_on_test, index=y_test.index)], axis=1)
    y_test.columns = [*y_test.columns[:-1], 'prediction']
    y_test.reset_index().to_sql(STAMP, if_exists='replace', schema='predictions', index=False, con=db_engine())

if VERBOSE > 0:
    process = psutil.Process(os.getpid())
    print('memory used:', round(process.memory_info().rss / (2 ** 30), 1), 'GB')
